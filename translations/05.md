---
title: "[译] 构建一个 Python 编译器和解释器 - 05 语句"
description:
- 在构建 Python 编译器和解释器系列的第五部分，我们将在程序中添加对多语句的支持。
---

## 构建 Python 编译器和解释器

本文是 ["构建 Python 编译器和解释器"](https://mathspp.com/blog/tag:bpci) 系列的第五篇文章，因此在阅读本文之前，请确保您已经阅读了前四篇文章！

[GitHub 代码库中的 v0.4.0 标签代码](https://github.com/mathspp/building-a-python-compiler-and-interpreter/tree/v0.4.0)是作为本文起点的代码。

## 目标

本文的目的是确保我们的程序可以由一系列语句组成（与 Python 一样用换行分隔）。目前，我们只能运行单行代码：

``` Python
❯ python -m python.interpreter "1 + 2
3 + 4
5 + 6"
RuntimeError: Can't tokenize '\n'.
```

我们将在本文中对此进行修改。

## 处理多个语句

### 分词

为了处理多语句，我们需要能够标记语句分隔符（换行符）。因此，我们首先要引入这种标记类型：

``` Python
class TokenType(StrEnum):
    # ...
    NEWLINE = auto()  # statement separator
```

现在，我们可能想在映射 `CHARS_AS_TOKENS` 中添加换行符 `\n`。这样就可以将换行符标记化了。

但是，如果我们这样做，就会产生与代码中换行符一样多的 `NEWLINE` 标记，即使一行中有多个空行也是如此。这并没有什么帮助，因为我们只关心在某些代码后出现的换行符。

我们将修改分词器来处理这个问题。我们将创建一个 `beginning_of_line` 属性，它将决定我们是否在这一行中生成了任何标记。如果我们碰到一个换行符，而 `beginning_of_line` 属性为 `True`，那是因为我们还没有在这一行中做任何事情，因此我们不想生成一个 `NEWLINE` 标记。

因此，分词器被修改成这样：

``` Python
class Tokenizer:
    def __init__(self, code: str) -> None:
        self.code = code
        self.ptr: int = 0
        self.beginning_of_line = True

    # ...

    def next_token(self) -> Token:
        while self.ptr < len(self.code) and self.code[self.ptr] == " ":
            self.ptr += 1

        if self.ptr == len(self.code):
            return Token(TokenType.EOF)

        # Handle the newline case.
        char = self.code[self.ptr]
        if char == "\n":
            self.ptr += 1
            if not self.beginning_of_line:
                self.beginning_of_line = True
                return Token(TokenType.NEWLINE)
            else:  # If we're at the BoL, get the next token instead.
                return self.next_token()

        # If we got to this point, we're about to produce another token
        # so we can set BoL to False.
        self.beginning_of_line = False
        if self.peek(length=2) == "**":
            self.ptr += 2
            return Token(TokenType.EXP)
        # Other cases here...
```

> 如果你想知道，当你没有经验时（就像我一样），要想知道这样做是 "最好的"，并不是一件稀松平常事。很多时候，我决定以某种方式做事，但当我取得一些进展时，我才意识到我应该以另一种方式来做。我只是想在这些文章中为这些错误的决定提供一些捷径......虽然这些决定肯定会发生！

现在，我们为分词器添加测试。我们需要确保能标记换行符，还需要确保空换行符 / 连续换行符被忽略：

``` Python
@pytest.mark.parametrize(
    "code",
    [
        ("\n\n\n1 + 2\n3 + 4\n"),  # Extras at the beginning.
        ("1 + 2\n\n\n3 + 4\n"),  # Extras in the middle.
        ("1 + 2\n3 + 4\n\n\n"),  # Extras at the end.
        ("\n\n\n1 + 2\n\n\n3 + 4\n\n\n"),  # Extras everywhere.
    ],
)
def test_tokenizer_ignores_extra_newlines(code: str):
    tokens = list(Tokenizer(code))
    assert tokens == [
        Token(TokenType.INT, 1),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 2),
        Token(TokenType.NEWLINE),
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 4),
        Token(TokenType.NEWLINE),
        Token(TokenType.EOF),
    ]
```

## 解析

接下来，我们需要更新语法，然后更新解析器。这是语法现在的样子：

``` Python
program := computation
computation := term ( (PLUS | MINUS) term )*
term := unary ( (MUL | DIV | MOD) unary )*
unary := PLUS unary | MINUS unary | exponentiation
exponentiation := atom EXP unary | atom
atom := LPAREN computation RPAREN | number
number := INT | FLOAT
```

现在，我们想说的是，程序不再只是一个 `computation`，而是任意数量的 `computation`。我们可以通过编写这个新语法来做到这一点：

``` Python
program := statement* EOF

statement := expr_statement
expr_statement := computation NEWLINE

computation := term ( (PLUS | MINUS) term )*
term := unary ( (MUL | DIV | MOD) unary )*
unary := PLUS unary | MINUS unary | exponentiation
exponentiation := atom EXP unary | atom
atom := LPAREN computation RPAREN | number
number := INT | FLOAT
```

目前，规则 `statement` 只有一个选项（`expr`），但一旦我们添加了赋值、条件和循环等内容，情况将会发生变化。

现在，我们要添加 / 更改与我们创建 / 更改的规则相关联的解析方法：

- `program`
- `statement`
- `expr`

但首先，我们需要为解析器创建适当的树节点：

- 我们会说，`Program` 包含一系列语句；
- 我们将创建一个节点 `Statement`，它不会被直接实例化，但会被不同类型的语句继承；以及
- 我们将创建一个节点 `ExprStatement` （继承自 `Statement`）用于表达式并作为语句单独存在。

但我为什么不把 `Expr` 改为继承自 `Statement` 呢？因为这意味着像 `BinOp` 这样的东西也是语句，而这是不准确的。表达式可以作为语句，但有很多地方接受表达式而不接受语句，因此创建一个所有表达式都是语句的层次结构是很别扭的。

于是，我想了想，意识到我更喜欢这种方式。这是最好的方法吗？我也不知道！🤣

下面是新的树节点：

``` Python
from __future__ import annotations
# ...

@dataclass
class Program(TreeNode):
    statements: list[Statement]

@dataclass
class Statement(TreeNode):
    pass

@dataclass
class ExprStatement(Statement):
    expr: Expr
```

现在我们有了相应的节点，就可以解析新的 / 修改过的语法规则了：

``` Python
class Parser:
    # ...

    def parse_expr_statement(self) -> ExprStatement:
        """Parses a standalone expression."""
        expr = ExprStatement(self.parse_computation())
        self.eat(TokenType.NEWLINE)
        return expr

    def parse_statement(self) -> Statement:
        """Parses a statement."""
        return self.parse_expr_statement()

    def parse(self) -> Program:  # <-- changed
        """Parses the program."""
        program = Program([])
        while self.peek() != TokenType.EOF:
            program.statements.append(self.parse_statement())
        self.eat(TokenType.EOF)
        return program
```

现在我们应该运行我们的测试，以确保没有任何问题...结果有 50 个测试失败！到底发生了什么？

我们刚刚改变了完整程序的解析方式，因此之前的测试很可能会因为假定程序是以特定方式解析的而被破坏。有两种方法可以修复这些测试：

1. 修正它们，使它们仍然代表完整的程序。
2. 我们不调用顶层方法 `Parser.parse`，而是调用负责解析该部分树的方法。

我选择了方案 2，这意味着我必须从所有解析器测试中移除 `EOF` 标记，并将对 `parse` 的调用替换为对 `parse_computation` 的调用。

例如，请看测试 `test_parsing_addition`：

``` Python
def test_parsing_addition():
    tokens = [
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 5),
        Token(TokenType.EOF),
    ]
    tree = Parser(tokens).parse()
    assert tree == BinOp(
        "+",
        Int(3),
        Int(5),
    )
```

测试现在看起来是这样的：

``` Python
def test_parsing_addition():
    tokens = [
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 5),
    ]
    tree = Parser(tokens).parse_computation()
    assert tree == BinOp(
        "+",
        Int(3),
        Int(5),
    )
```

现在，再次运行测试会发现所有（或大部分）解释器测试都被破坏了，因此我们仍需修复。我们对语法所做的修改现在要求程序以换行结束，这是新的限制，这就是为什么解释器测试会抱怨 `NEWLINE` 和 `EOF` 标记。

语法可以重写，这样程序就不需要以换行符结束，但现在我还不知道如何以合适的方式做到这一点。相反，我们可以厚着脸皮，在实例化标记符时，在代码末尾添加一个换行符 `\n`：

``` Python
class Tokenizer:
    def __init__(self, code: str) -> None:
        self.code = code + "\n"  # Ensure the program ends with a newline.
```

现在，我们所有的程序都以换行符结束，这意味着每当我们标记一个程序时，它都会以换行符和文件结束符结束。这意味着我们需要快速修复所有标记符测试。

完成这些工作后，我们就只剩下修复解释器测试了。然而，解释器测试失败的原因是我们正在生成一个新的（更完整的）树结构，而编译器还无法编译它。

因此，我们实际上只需继续下去。在进入编译器阶段之前，我们先修复一下我们的辅助方法 `print_ast`：

``` Python
def print_ast(tree: TreeNode, depth: int = 0) -> None:
    indent = "    " * depth
    node_name = tree.__class__.__name__
    match tree:
        case Program(statements):
            print(f"{indent}{node_name}([\n", end="")
            for statement in statements:
                print_ast(statement, depth + 1)
                print(",")
            print(f",\n{indent}])", end="")
        case ExprStatement(expr):
            print(f"{indent}{node_name}(\n", end="")
            print_ast(expr, depth + 1)
            print(f",\n{indent})", end="")
        case UnaryOp(op, value):
            print(f"{indent}{node_name}(\n{indent}    {op!r},")
            print_ast(value, depth + 1)
            print(f",\n{indent})", end="")
        case BinOp(op, left, right):
            print(f"{indent}{node_name}(\n{indent}    {op!r},")
            print_ast(left, depth + 1)
            print(",")
            print_ast(right, depth + 1)
            print(f",\n{indent})", end="")
        case Int(value) | Float(value):
            print(f"{indent}{node_name}({value!r})", end="")
        case _:
            raise RuntimeError(f"Can't print a node of type {node_name}")
    if depth == 0:
        print()
```

在 `parser.py` 文件的底部，我添加了这段代码来测试这一点：

``` Python
if __name__ == "__main__":
    from .tokenizer import Tokenizer

    code = """1 % -2
5 ** -3 / 5
1 * 2 + 2 ** 3"""
    parser = Parser(list(Tokenizer(code)))
    print_ast(parser.parse())
```

使用 `python -m python.parser` 运行代码将产生以下输出：

``` Python
Program([
    ExprStatement(
        BinOp(
            '%',
            Int(1),
            UnaryOp(
                '-',
                Int(2),
            ),
        ),
    ),
    ExprStatement(
        BinOp(
            '/',
            BinOp(
                '**',
                Int(5),
                UnaryOp(
                    '-',
                    Int(3),
                ),
            ),
            Int(5),
        ),
    ),
    ExprStatement(
        BinOp(
            '+',
            BinOp(
                '*',
                Int(1),
                Int(2),
            ),
            BinOp(
                '**',
                Int(2),
                Int(3),
            ),
        ),
    ),
])
```

检查树并确保它看起来正确后，我们就可以将其作为解析器的新测试：

``` Python
def test_parsing_multiple_statements():
    code = "1 % -2\n5 ** -3 / 5\n1 * 2 + 2 ** 3\n"
    tree = Parser(list(Tokenizer(code))).parse()
    assert tree == Program(...)  # Tree from above.
```

## 编译

下一步是确保编译器知道如何处理新的树节点 `Program` 和 `ExprStatement`，不过值得庆幸的是，这两个节点都很简单！要编译节点 `Program`，我们只需按顺序编译每条语句：

``` Python
class Compiler:
    # ...

    def compile_Program(self, program: Program) -> BytecodeGenerator:
        for statement in program.statements:
            yield from self._compile(statement)
```

节点 `ExprStatement` 可能更简单！我们只需要编译它的表达式...并添加一条 `POP` 指令。为什么？

假设没有 `POP` 指令。假设编译节点 `ExprStatement` 只相当于编译其表达式：

``` Python
class Compiler:
    # ...

    def compile_ExprStatement(self, expression: ExprStatement) -> BytecodeGenerator:
        yield from self._compile(expression.expr)
```

现在，如果运行一段包含多个表达式的代码，程序执行结束时你会看到什么？下面就是一个例子：

``` Python
❯ python -m python.interpreter "1 + 2
∙ 3 + 4
∙ 5 + 6"
Done!
Stack([3, 7, 11])
```

因为有三行代码，所以最终堆栈中有三个元素！之前表达式的临时结果被留在了栈中。这没有什么意义，所以我们应该创建一个字节码操作符 `POP`，它的唯一任务就是从栈中弹出最上面的元素。

因此，我们创建了新的字节码操作符，并在编译 `ExprStatement` 类型的节点时使用它：

``` Python
class BytecodeType(StrEnum):
    # ...
    POP = auto()

# ...

class Compiler:
    # ...

    def compile_ExprStatement(self, expression: ExprStatement) -> BytecodeGenerator:
        yield from self._compile(expression.expr)
        yield Bytecode(BytecodeType.POP)
```

现在，我们可以编写一个测试，对 `Program` 和 `ExprStatement` 类型的节点进行编译：

``` Python
def test_compile_program_and_expr_statement():
    tree = Program(
        [
            ExprStatement(Int(1)),
            ExprStatement(Float(2.0)),
            ExprStatement(BinOp("+", Float(3.0), Float(4.0))),
        ]
    )
    bytecode = list(Compiler(tree).compile())
    assert bytecode == [
        Bytecode(BytecodeType.PUSH, 1),
        Bytecode(BytecodeType.POP),
        Bytecode(BytecodeType.PUSH, 2.0),
        Bytecode(BytecodeType.POP),
        Bytecode(BytecodeType.PUSH, 3.0),
        Bytecode(BytecodeType.PUSH, 4.0),
        Bytecode(BytecodeType.BINOP, "+"),
        Bytecode(BytecodeType.POP),
    ]
```

最后，我们可以解释我们的程序...

## 解释

唯一需要对解释器进行的修改是，我们可以处理新的字节码运算符 `POP`：

``` Python
from typing import Any

# ...

class Interpreter:
    def __init__(self, bytecode: list[Bytecode]) -> None:
        # ...
        self.last_value_popped: Any = None

    # ...

    def interpret_pop(self, bc: Bytecode) -> None:
        self.last_value_popped = self.stack.pop()
```

您可能已经注意到，在解释弹出时，我将弹出值赋值给属性 `last_value_popped`。

由于我们还不支持变量或打印，该属性用于调试，这样我们就能知道最后从堆栈中弹出的值是什么。这也将确保我们能够修复所有解释器错误。

事实上，如果将文件 `tests/test_interpreter.py` 中辅助函数 `run_computation` 中的 `interpreter.stack.pop()` 返回值替换为 `interpreter.last_value_popped` 返回值，解释器测试就会全部通过：

``` Python
def run_computation(code: str) -> int:
    tokens = list(Tokenizer(code))
    tree = Parser(tokens).parse()
    bytecode = list(Compiler(tree).compile())
    interpreter = Interpreter(bytecode)
    interpreter.interpret()
    return interpreter.last_value_popped  # <-- Changed!
```

现在我们运行测试：

``` Python
❯ pytest .
========================== test session starts ==========================
platform darwin -- Python 3.12.0, pytest-7.4.2, pluggy-1.3.0
rootdir: /Users/rodrigogs/Documents/python
plugins: anyio-3.7.1
collected 103 items

tests/test_compiler.py ...........                                [ 10%]
tests/test_interpreter.py ....................................    [ 45%]
tests/test_parser.py ......................                       [ 66%]
tests/test_tokenizer.py ..................................        [100%]

========================== 103 passed in 0.05s ==========================
```

我们还可以更改方法 `interpret` 的结尾，打印最后弹出的值而不是栈：

``` Python
class Interpreter:
    # ...

    def interpret(self) -> None:
        # ...

        print("Done!")
        print(self.last_value_popped)
```

现在，我们不会在代码中有多个语句的地方添加测试，因为我们没有有效的方法来确保中间语句产生正确的结果（尽管它们很可能是正确的）。相反，我们将等到变量赋值（下一步就会有！）时再进行检查。

## 回顾

在本文中，我们重写了程序，以便能够处理多语句。这需要：

- 为换行符添加新的标记类型；
- 修改分词器，使其忽略连续的空行；
- 修改分词器，强制所有程序以换行符结束；
- 重写语言语法，允许程序由多个语句组成；
- 引入新的树节点来表示程序、语句和仅由表达式组成的语句；
- 编译新的节点类型；
- 创建一个新的字节码运算符；以及
- 更改解释器，以处理新的字节码操作符。

这篇文章是一个很好的例子，说明了看似简单的事情如何对计划产生巨大的影响。

您可以在此 GitHub 代码库的 [v0.5.0 标签](https://github.com/mathspp/building-a-python-compiler-and-interpreter/tree/v0.5.0)中获取本文的代码。

> 译者注：我的代码在[这里](https://github.com/imkasen/bpci/tree/v0.5.0)。

## 练习

- 更改分词器，开始将字符序列识别为变量名。
- 你能创建一组因为是关键字而无效的变量名吗？
- 更改语法，使程序由计算和变量赋值组成，并相应更新解析器。
- 更改语法，使 `number` 实际上是一个数字或变量引用，并相应地更新解析器。
