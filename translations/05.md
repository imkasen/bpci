---
title: "[è¯‘] æ„å»ºä¸€ä¸ª Python ç¼–è¯‘å™¨å’Œè§£é‡Šå™¨ - 05 è¯­å¥"
description:
- åœ¨æ„å»º Python ç¼–è¯‘å™¨å’Œè§£é‡Šå™¨ç³»åˆ—çš„ç¬¬äº”éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†åœ¨ç¨‹åºä¸­æ·»åŠ å¯¹å¤šè¯­å¥çš„æ”¯æŒã€‚
---

## æ„å»º Python ç¼–è¯‘å™¨å’Œè§£é‡Šå™¨

æœ¬æ–‡æ˜¯ ["æ„å»º Python ç¼–è¯‘å™¨å’Œè§£é‡Šå™¨"](https://mathspp.com/blog/tag:bpci) ç³»åˆ—çš„ç¬¬äº”ç¯‡æ–‡ç« ï¼Œå› æ­¤åœ¨é˜…è¯»æœ¬æ–‡ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ç»é˜…è¯»äº†å‰å››ç¯‡æ–‡ç« ï¼

[GitHub ä»£ç åº“ä¸­çš„ v0.4.0 æ ‡ç­¾ä»£ç ](https://github.com/mathspp/building-a-python-compiler-and-interpreter/tree/v0.4.0)æ˜¯ä½œä¸ºæœ¬æ–‡èµ·ç‚¹çš„ä»£ç ã€‚

## ç›®æ ‡

æœ¬æ–‡çš„ç›®çš„æ˜¯ç¡®ä¿æˆ‘ä»¬çš„ç¨‹åºå¯ä»¥ç”±ä¸€ç³»åˆ—è¯­å¥ç»„æˆï¼ˆä¸ Python ä¸€æ ·ç”¨æ¢è¡Œåˆ†éš”ï¼‰ã€‚ç›®å‰ï¼Œæˆ‘ä»¬åªèƒ½è¿è¡Œå•è¡Œä»£ç ï¼š

``` Python
â¯ python -m python.interpreter "1 + 2
3 + 4
5 + 6"
RuntimeError: Can't tokenize '\n'.
```

æˆ‘ä»¬å°†åœ¨æœ¬æ–‡ä¸­å¯¹æ­¤è¿›è¡Œä¿®æ”¹ã€‚

## å¤„ç†å¤šä¸ªè¯­å¥

### åˆ†è¯

ä¸ºäº†å¤„ç†å¤šè¯­å¥ï¼Œæˆ‘ä»¬éœ€è¦èƒ½å¤Ÿæ ‡è®°è¯­å¥åˆ†éš”ç¬¦ï¼ˆæ¢è¡Œç¬¦ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆè¦å¼•å…¥è¿™ç§æ ‡è®°ç±»å‹ï¼š

``` Python
class TokenType(StrEnum):
    # ...
    NEWLINE = auto()  # statement separator
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³åœ¨æ˜ å°„ `CHARS_AS_TOKENS` ä¸­æ·»åŠ æ¢è¡Œç¬¦ `\n`ã€‚è¿™æ ·å°±å¯ä»¥å°†æ¢è¡Œç¬¦æ ‡è®°åŒ–äº†ã€‚

ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬è¿™æ ·åšï¼Œå°±ä¼šäº§ç”Ÿä¸ä»£ç ä¸­æ¢è¡Œç¬¦ä¸€æ ·å¤šçš„ `NEWLINE` æ ‡è®°ï¼Œå³ä½¿ä¸€è¡Œä¸­æœ‰å¤šä¸ªç©ºè¡Œä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™å¹¶æ²¡æœ‰ä»€ä¹ˆå¸®åŠ©ï¼Œå› ä¸ºæˆ‘ä»¬åªå…³å¿ƒåœ¨æŸäº›ä»£ç åå‡ºç°çš„æ¢è¡Œç¬¦ã€‚

æˆ‘ä»¬å°†ä¿®æ”¹åˆ†è¯å™¨æ¥å¤„ç†è¿™ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª `beginning_of_line` å±æ€§ï¼Œå®ƒå°†å†³å®šæˆ‘ä»¬æ˜¯å¦åœ¨è¿™ä¸€è¡Œä¸­ç”Ÿæˆäº†ä»»ä½•æ ‡è®°ã€‚å¦‚æœæˆ‘ä»¬ç¢°åˆ°ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œè€Œ `beginning_of_line` å±æ€§ä¸º `True`ï¼Œé‚£æ˜¯å› ä¸ºæˆ‘ä»¬è¿˜æ²¡æœ‰åœ¨è¿™ä¸€è¡Œä¸­åšä»»ä½•äº‹æƒ…ï¼Œå› æ­¤æˆ‘ä»¬ä¸æƒ³ç”Ÿæˆä¸€ä¸ª `NEWLINE` æ ‡è®°ã€‚

å› æ­¤ï¼Œåˆ†è¯å™¨è¢«ä¿®æ”¹æˆè¿™æ ·ï¼š

``` Python
class Tokenizer:
    def __init__(self, code: str) -> None:
        self.code = code
        self.ptr: int = 0
        self.beginning_of_line = True

    # ...

    def next_token(self) -> Token:
        while self.ptr < len(self.code) and self.code[self.ptr] == " ":
            self.ptr += 1

        if self.ptr == len(self.code):
            return Token(TokenType.EOF)

        # Handle the newline case.
        char = self.code[self.ptr]
        if char == "\n":
            self.ptr += 1
            if not self.beginning_of_line:
                self.beginning_of_line = True
                return Token(TokenType.NEWLINE)
            else:  # If we're at the BoL, get the next token instead.
                return self.next_token()

        # If we got to this point, we're about to produce another token
        # so we can set BoL to False.
        self.beginning_of_line = False
        if self.peek(length=2) == "**":
            self.ptr += 2
            return Token(TokenType.EXP)
        # Other cases here...
```

> å¦‚æœä½ æƒ³çŸ¥é“ï¼Œå½“ä½ æ²¡æœ‰ç»éªŒæ—¶ï¼ˆå°±åƒæˆ‘ä¸€æ ·ï¼‰ï¼Œè¦æƒ³çŸ¥é“è¿™æ ·åšæ˜¯ "æœ€å¥½çš„"ï¼Œå¹¶ä¸æ˜¯ä¸€ä»¶ç¨€æ¾å¹³å¸¸äº‹ã€‚å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘å†³å®šä»¥æŸç§æ–¹å¼åšäº‹ï¼Œä½†å½“æˆ‘å–å¾—ä¸€äº›è¿›å±•æ—¶ï¼Œæˆ‘æ‰æ„è¯†åˆ°æˆ‘åº”è¯¥ä»¥å¦ä¸€ç§æ–¹å¼æ¥åšã€‚æˆ‘åªæ˜¯æƒ³åœ¨è¿™äº›æ–‡ç« ä¸­ä¸ºè¿™äº›é”™è¯¯çš„å†³å®šæä¾›ä¸€äº›æ·å¾„......è™½ç„¶è¿™äº›å†³å®šè‚¯å®šä¼šå‘ç”Ÿï¼

ç°åœ¨ï¼Œæˆ‘ä»¬ä¸ºåˆ†è¯å™¨æ·»åŠ æµ‹è¯•ã€‚æˆ‘ä»¬éœ€è¦ç¡®ä¿èƒ½æ ‡è®°æ¢è¡Œç¬¦ï¼Œè¿˜éœ€è¦ç¡®ä¿ç©ºæ¢è¡Œç¬¦ / è¿ç»­æ¢è¡Œç¬¦è¢«å¿½ç•¥ï¼š

``` Python
@pytest.mark.parametrize(
    "code",
    [
        ("\n\n\n1 + 2\n3 + 4\n"),  # Extras at the beginning.
        ("1 + 2\n\n\n3 + 4\n"),  # Extras in the middle.
        ("1 + 2\n3 + 4\n\n\n"),  # Extras at the end.
        ("\n\n\n1 + 2\n\n\n3 + 4\n\n\n"),  # Extras everywhere.
    ],
)
def test_tokenizer_ignores_extra_newlines(code: str):
    tokens = list(Tokenizer(code))
    assert tokens == [
        Token(TokenType.INT, 1),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 2),
        Token(TokenType.NEWLINE),
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 4),
        Token(TokenType.NEWLINE),
        Token(TokenType.EOF),
    ]
```

## è§£æ

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ–°è¯­æ³•ï¼Œç„¶åæ›´æ–°è§£æå™¨ã€‚è¿™æ˜¯è¯­æ³•ç°åœ¨çš„æ ·å­ï¼š

``` Python
program := computation
computation := term ( (PLUS | MINUS) term )*
term := unary ( (MUL | DIV | MOD) unary )*
unary := PLUS unary | MINUS unary | exponentiation
exponentiation := atom EXP unary | atom
atom := LPAREN computation RPAREN | number
number := INT | FLOAT
```

ç°åœ¨ï¼Œæˆ‘ä»¬æƒ³è¯´çš„æ˜¯ï¼Œç¨‹åºä¸å†åªæ˜¯ä¸€ä¸ª `computation`ï¼Œè€Œæ˜¯ä»»æ„æ•°é‡çš„ `computation`ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ç¼–å†™è¿™ä¸ªæ–°è¯­æ³•æ¥åšåˆ°è¿™ä¸€ç‚¹ï¼š

``` Python
program := statement* EOF

statement := expr_statement
expr_statement := computation NEWLINE

computation := term ( (PLUS | MINUS) term )*
term := unary ( (MUL | DIV | MOD) unary )*
unary := PLUS unary | MINUS unary | exponentiation
exponentiation := atom EXP unary | atom
atom := LPAREN computation RPAREN | number
number := INT | FLOAT
```

ç›®å‰ï¼Œè§„åˆ™ `statement` åªæœ‰ä¸€ä¸ªé€‰é¡¹ï¼ˆ`expr`ï¼‰ï¼Œä½†ä¸€æ—¦æˆ‘ä»¬æ·»åŠ äº†èµ‹å€¼ã€æ¡ä»¶å’Œå¾ªç¯ç­‰å†…å®¹ï¼Œæƒ…å†µå°†ä¼šå‘ç”Ÿå˜åŒ–ã€‚

ç°åœ¨ï¼Œæˆ‘ä»¬è¦æ·»åŠ  / æ›´æ”¹ä¸æˆ‘ä»¬åˆ›å»º / æ›´æ”¹çš„è§„åˆ™ç›¸å…³è”çš„è§£ææ–¹æ³•ï¼š

- `program`
- `statement`
- `expr`

ä½†é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸ºè§£æå™¨åˆ›å»ºé€‚å½“çš„æ ‘èŠ‚ç‚¹ï¼š

- æˆ‘ä»¬ä¼šè¯´ï¼Œ`Program` åŒ…å«ä¸€ç³»åˆ—è¯­å¥ï¼›
- æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªèŠ‚ç‚¹ `Statement`ï¼Œå®ƒä¸ä¼šè¢«ç›´æ¥å®ä¾‹åŒ–ï¼Œä½†ä¼šè¢«ä¸åŒç±»å‹çš„è¯­å¥ç»§æ‰¿ï¼›ä»¥åŠ
- æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªèŠ‚ç‚¹ `ExprStatement` ï¼ˆç»§æ‰¿è‡ª `Statement`ï¼‰ç”¨äºè¡¨è¾¾å¼å¹¶ä½œä¸ºè¯­å¥å•ç‹¬å­˜åœ¨ã€‚

ä½†æˆ‘ä¸ºä»€ä¹ˆä¸æŠŠ `Expr` æ”¹ä¸ºç»§æ‰¿è‡ª `Statement` å‘¢ï¼Ÿå› ä¸ºè¿™æ„å‘³ç€åƒ `BinOp` è¿™æ ·çš„ä¸œè¥¿ä¹Ÿæ˜¯è¯­å¥ï¼Œè€Œè¿™æ˜¯ä¸å‡†ç¡®çš„ã€‚è¡¨è¾¾å¼å¯ä»¥ä½œä¸ºè¯­å¥ï¼Œä½†æœ‰å¾ˆå¤šåœ°æ–¹æ¥å—è¡¨è¾¾å¼è€Œä¸æ¥å—è¯­å¥ï¼Œå› æ­¤åˆ›å»ºä¸€ä¸ªæ‰€æœ‰è¡¨è¾¾å¼éƒ½æ˜¯è¯­å¥çš„å±‚æ¬¡ç»“æ„æ˜¯å¾ˆåˆ«æ‰­çš„ã€‚

äºæ˜¯ï¼Œæˆ‘æƒ³äº†æƒ³ï¼Œæ„è¯†åˆ°æˆ‘æ›´å–œæ¬¢è¿™ç§æ–¹å¼ã€‚è¿™æ˜¯æœ€å¥½çš„æ–¹æ³•å—ï¼Ÿæˆ‘ä¹Ÿä¸çŸ¥é“ï¼ğŸ¤£

ä¸‹é¢æ˜¯æ–°çš„æ ‘èŠ‚ç‚¹ï¼š

``` Python
from __future__ import annotations
# ...

@dataclass
class Program(TreeNode):
    statements: list[Statement]

@dataclass
class Statement(TreeNode):
    pass

@dataclass
class ExprStatement(Statement):
    expr: Expr
```

ç°åœ¨æˆ‘ä»¬æœ‰äº†ç›¸åº”çš„èŠ‚ç‚¹ï¼Œå°±å¯ä»¥è§£ææ–°çš„ / ä¿®æ”¹è¿‡çš„è¯­æ³•è§„åˆ™äº†ï¼š

``` Python
class Parser:
    # ...

    def parse_expr_statement(self) -> ExprStatement:
        """Parses a standalone expression."""
        expr = ExprStatement(self.parse_computation())
        self.eat(TokenType.NEWLINE)
        return expr

    def parse_statement(self) -> Statement:
        """Parses a statement."""
        return self.parse_expr_statement()

    def parse(self) -> Program:  # <-- changed
        """Parses the program."""
        program = Program([])
        while self.peek() != TokenType.EOF:
            program.statements.append(self.parse_statement())
        self.eat(TokenType.EOF)
        return program
```

ç°åœ¨æˆ‘ä»¬åº”è¯¥è¿è¡Œæˆ‘ä»¬çš„æµ‹è¯•ï¼Œä»¥ç¡®ä¿æ²¡æœ‰ä»»ä½•é—®é¢˜...ç»“æœæœ‰ 50 ä¸ªæµ‹è¯•å¤±è´¥ï¼åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

æˆ‘ä»¬åˆšåˆšæ”¹å˜äº†å®Œæ•´ç¨‹åºçš„è§£ææ–¹å¼ï¼Œå› æ­¤ä¹‹å‰çš„æµ‹è¯•å¾ˆå¯èƒ½ä¼šå› ä¸ºå‡å®šç¨‹åºæ˜¯ä»¥ç‰¹å®šæ–¹å¼è§£æçš„è€Œè¢«ç ´åã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥ä¿®å¤è¿™äº›æµ‹è¯•ï¼š

1. ä¿®æ­£å®ƒä»¬ï¼Œä½¿å®ƒä»¬ä»ç„¶ä»£è¡¨å®Œæ•´çš„ç¨‹åºã€‚
2. æˆ‘ä»¬ä¸è°ƒç”¨é¡¶å±‚æ–¹æ³• `Parser.parse`ï¼Œè€Œæ˜¯è°ƒç”¨è´Ÿè´£è§£æè¯¥éƒ¨åˆ†æ ‘çš„æ–¹æ³•ã€‚

æˆ‘é€‰æ‹©äº†æ–¹æ¡ˆ 2ï¼Œè¿™æ„å‘³ç€æˆ‘å¿…é¡»ä»æ‰€æœ‰è§£æå™¨æµ‹è¯•ä¸­ç§»é™¤ `EOF` æ ‡è®°ï¼Œå¹¶å°†å¯¹ `parse` çš„è°ƒç”¨æ›¿æ¢ä¸ºå¯¹ `parse_computation` çš„è°ƒç”¨ã€‚

ä¾‹å¦‚ï¼Œè¯·çœ‹æµ‹è¯• `test_parsing_addition`ï¼š

``` Python
def test_parsing_addition():
    tokens = [
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 5),
        Token(TokenType.EOF),
    ]
    tree = Parser(tokens).parse()
    assert tree == BinOp(
        "+",
        Int(3),
        Int(5),
    )
```

æµ‹è¯•ç°åœ¨çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š

``` Python
def test_parsing_addition():
    tokens = [
        Token(TokenType.INT, 3),
        Token(TokenType.PLUS),
        Token(TokenType.INT, 5),
    ]
    tree = Parser(tokens).parse_computation()
    assert tree == BinOp(
        "+",
        Int(3),
        Int(5),
    )
```

ç°åœ¨ï¼Œå†æ¬¡è¿è¡Œæµ‹è¯•ä¼šå‘ç°æ‰€æœ‰ï¼ˆæˆ–å¤§éƒ¨åˆ†ï¼‰è§£é‡Šå™¨æµ‹è¯•éƒ½è¢«ç ´åäº†ï¼Œå› æ­¤æˆ‘ä»¬ä»éœ€ä¿®å¤ã€‚æˆ‘ä»¬å¯¹è¯­æ³•æ‰€åšçš„ä¿®æ”¹ç°åœ¨è¦æ±‚ç¨‹åºä»¥æ¢è¡Œç»“æŸï¼Œè¿™æ˜¯æ–°çš„é™åˆ¶ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆè§£é‡Šå™¨æµ‹è¯•ä¼šæŠ±æ€¨ `NEWLINE` å’Œ `EOF` æ ‡è®°ã€‚

è¯­æ³•å¯ä»¥é‡å†™ï¼Œè¿™æ ·ç¨‹åºå°±ä¸éœ€è¦ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œä½†ç°åœ¨æˆ‘è¿˜ä¸çŸ¥é“å¦‚ä½•ä»¥åˆé€‚çš„æ–¹å¼åšåˆ°è¿™ä¸€ç‚¹ã€‚ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥åšç€è„¸çš®ï¼Œåœ¨å®ä¾‹åŒ–æ ‡è®°ç¬¦æ—¶ï¼Œåœ¨ä»£ç æœ«å°¾æ·»åŠ ä¸€ä¸ªæ¢è¡Œç¬¦ `\n`ï¼š

``` Python
class Tokenizer:
    def __init__(self, code: str) -> None:
        self.code = code + "\n"  # Ensure the program ends with a newline.
```

ç°åœ¨ï¼Œæˆ‘ä»¬æ‰€æœ‰çš„ç¨‹åºéƒ½ä»¥æ¢è¡Œç¬¦ç»“æŸï¼Œè¿™æ„å‘³ç€æ¯å½“æˆ‘ä»¬æ ‡è®°ä¸€ä¸ªç¨‹åºæ—¶ï¼Œå®ƒéƒ½ä¼šä»¥æ¢è¡Œç¬¦å’Œæ–‡ä»¶ç»“æŸç¬¦ç»“æŸã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦å¿«é€Ÿä¿®å¤æ‰€æœ‰æ ‡è®°ç¬¦æµ‹è¯•ã€‚

å®Œæˆè¿™äº›å·¥ä½œåï¼Œæˆ‘ä»¬å°±åªå‰©ä¸‹ä¿®å¤è§£é‡Šå™¨æµ‹è¯•äº†ã€‚ç„¶è€Œï¼Œè§£é‡Šå™¨æµ‹è¯•å¤±è´¥çš„åŸå› æ˜¯æˆ‘ä»¬æ­£åœ¨ç”Ÿæˆä¸€ä¸ªæ–°çš„ï¼ˆæ›´å®Œæ•´çš„ï¼‰æ ‘ç»“æ„ï¼Œè€Œç¼–è¯‘å™¨è¿˜æ— æ³•ç¼–è¯‘å®ƒã€‚

å› æ­¤ï¼Œæˆ‘ä»¬å®é™…ä¸Šåªéœ€ç»§ç»­ä¸‹å»ã€‚åœ¨è¿›å…¥ç¼–è¯‘å™¨é˜¶æ®µä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆä¿®å¤ä¸€ä¸‹æˆ‘ä»¬çš„è¾…åŠ©æ–¹æ³• `print_ast`ï¼š

``` Python
def print_ast(tree: TreeNode, depth: int = 0) -> None:
    indent = "    " * depth
    node_name = tree.__class__.__name__
    match tree:
        case Program(statements):
            print(f"{indent}{node_name}([\n", end="")
            for statement in statements:
                print_ast(statement, depth + 1)
                print(",")
            print(f",\n{indent}])", end="")
        case ExprStatement(expr):
            print(f"{indent}{node_name}(\n", end="")
            print_ast(expr, depth + 1)
            print(f",\n{indent})", end="")
        case UnaryOp(op, value):
            print(f"{indent}{node_name}(\n{indent}    {op!r},")
            print_ast(value, depth + 1)
            print(f",\n{indent})", end="")
        case BinOp(op, left, right):
            print(f"{indent}{node_name}(\n{indent}    {op!r},")
            print_ast(left, depth + 1)
            print(",")
            print_ast(right, depth + 1)
            print(f",\n{indent})", end="")
        case Int(value) | Float(value):
            print(f"{indent}{node_name}({value!r})", end="")
        case _:
            raise RuntimeError(f"Can't print a node of type {node_name}")
    if depth == 0:
        print()
```

åœ¨ `parser.py` æ–‡ä»¶çš„åº•éƒ¨ï¼Œæˆ‘æ·»åŠ äº†è¿™æ®µä»£ç æ¥æµ‹è¯•è¿™ä¸€ç‚¹ï¼š

``` Python
if __name__ == "__main__":
    from .tokenizer import Tokenizer

    code = """1 % -2
5 ** -3 / 5
1 * 2 + 2 ** 3"""
    parser = Parser(list(Tokenizer(code)))
    print_ast(parser.parse())
```

ä½¿ç”¨ `python -m python.parser` è¿è¡Œä»£ç å°†äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼š

``` Python
Program([
    ExprStatement(
        BinOp(
            '%',
            Int(1),
            UnaryOp(
                '-',
                Int(2),
            ),
        ),
    ),
    ExprStatement(
        BinOp(
            '/',
            BinOp(
                '**',
                Int(5),
                UnaryOp(
                    '-',
                    Int(3),
                ),
            ),
            Int(5),
        ),
    ),
    ExprStatement(
        BinOp(
            '+',
            BinOp(
                '*',
                Int(1),
                Int(2),
            ),
            BinOp(
                '**',
                Int(2),
                Int(3),
            ),
        ),
    ),
])
```

æ£€æŸ¥æ ‘å¹¶ç¡®ä¿å®ƒçœ‹èµ·æ¥æ­£ç¡®åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†å…¶ä½œä¸ºè§£æå™¨çš„æ–°æµ‹è¯•ï¼š

``` Python
def test_parsing_multiple_statements():
    code = "1 % -2\n5 ** -3 / 5\n1 * 2 + 2 ** 3\n"
    tree = Parser(list(Tokenizer(code))).parse()
    assert tree == Program(...)  # Tree from above.
```

## ç¼–è¯‘

ä¸‹ä¸€æ­¥æ˜¯ç¡®ä¿ç¼–è¯‘å™¨çŸ¥é“å¦‚ä½•å¤„ç†æ–°çš„æ ‘èŠ‚ç‚¹ `Program` å’Œ `ExprStatement`ï¼Œä¸è¿‡å€¼å¾—åº†å¹¸çš„æ˜¯ï¼Œè¿™ä¸¤ä¸ªèŠ‚ç‚¹éƒ½å¾ˆç®€å•ï¼è¦ç¼–è¯‘èŠ‚ç‚¹ `Program`ï¼Œæˆ‘ä»¬åªéœ€æŒ‰é¡ºåºç¼–è¯‘æ¯æ¡è¯­å¥ï¼š

``` Python
class Compiler:
    # ...

    def compile_Program(self, program: Program) -> BytecodeGenerator:
        for statement in program.statements:
            yield from self._compile(statement)
```

èŠ‚ç‚¹ `ExprStatement` å¯èƒ½æ›´ç®€å•ï¼æˆ‘ä»¬åªéœ€è¦ç¼–è¯‘å®ƒçš„è¡¨è¾¾å¼...å¹¶æ·»åŠ ä¸€æ¡ `POP` æŒ‡ä»¤ã€‚ä¸ºä»€ä¹ˆï¼Ÿ

å‡è®¾æ²¡æœ‰ `POP` æŒ‡ä»¤ã€‚å‡è®¾ç¼–è¯‘èŠ‚ç‚¹ `ExprStatement` åªç›¸å½“äºç¼–è¯‘å…¶è¡¨è¾¾å¼ï¼š

``` Python
class Compiler:
    # ...

    def compile_ExprStatement(self, expression: ExprStatement) -> BytecodeGenerator:
        yield from self._compile(expression.expr)
```

ç°åœ¨ï¼Œå¦‚æœè¿è¡Œä¸€æ®µåŒ…å«å¤šä¸ªè¡¨è¾¾å¼çš„ä»£ç ï¼Œç¨‹åºæ‰§è¡Œç»“æŸæ—¶ä½ ä¼šçœ‹åˆ°ä»€ä¹ˆï¼Ÿä¸‹é¢å°±æ˜¯ä¸€ä¸ªä¾‹å­ï¼š

``` Python
â¯ python -m python.interpreter "1 + 2
âˆ™ 3 + 4
âˆ™ 5 + 6"
Done!
Stack([3, 7, 11])
```

å› ä¸ºæœ‰ä¸‰è¡Œä»£ç ï¼Œæ‰€ä»¥æœ€ç»ˆå †æ ˆä¸­æœ‰ä¸‰ä¸ªå…ƒç´ ï¼ä¹‹å‰è¡¨è¾¾å¼çš„ä¸´æ—¶ç»“æœè¢«ç•™åœ¨äº†æ ˆä¸­ã€‚è¿™æ²¡æœ‰ä»€ä¹ˆæ„ä¹‰ï¼Œæ‰€ä»¥æˆ‘ä»¬åº”è¯¥åˆ›å»ºä¸€ä¸ªå­—èŠ‚ç æ“ä½œç¬¦ `POP`ï¼Œå®ƒçš„å”¯ä¸€ä»»åŠ¡å°±æ˜¯ä»æ ˆä¸­å¼¹å‡ºæœ€ä¸Šé¢çš„å…ƒç´ ã€‚

å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†æ–°çš„å­—èŠ‚ç æ“ä½œç¬¦ï¼Œå¹¶åœ¨ç¼–è¯‘ `ExprStatement` ç±»å‹çš„èŠ‚ç‚¹æ—¶ä½¿ç”¨å®ƒï¼š

``` Python
class BytecodeType(StrEnum):
    # ...
    POP = auto()

# ...

class Compiler:
    # ...

    def compile_ExprStatement(self, expression: ExprStatement) -> BytecodeGenerator:
        yield from self._compile(expression.expr)
        yield Bytecode(BytecodeType.POP)
```

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ªæµ‹è¯•ï¼Œå¯¹ `Program` å’Œ `ExprStatement` ç±»å‹çš„èŠ‚ç‚¹è¿›è¡Œç¼–è¯‘ï¼š

``` Python
def test_compile_program_and_expr_statement():
    tree = Program(
        [
            ExprStatement(Int(1)),
            ExprStatement(Float(2.0)),
            ExprStatement(BinOp("+", Float(3.0), Float(4.0))),
        ]
    )
    bytecode = list(Compiler(tree).compile())
    assert bytecode == [
        Bytecode(BytecodeType.PUSH, 1),
        Bytecode(BytecodeType.POP),
        Bytecode(BytecodeType.PUSH, 2.0),
        Bytecode(BytecodeType.POP),
        Bytecode(BytecodeType.PUSH, 3.0),
        Bytecode(BytecodeType.PUSH, 4.0),
        Bytecode(BytecodeType.BINOP, "+"),
        Bytecode(BytecodeType.POP),
    ]
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è§£é‡Šæˆ‘ä»¬çš„ç¨‹åº...

## è§£é‡Š

å”¯ä¸€éœ€è¦å¯¹è§£é‡Šå™¨è¿›è¡Œçš„ä¿®æ”¹æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥å¤„ç†æ–°çš„å­—èŠ‚ç è¿ç®—ç¬¦ `POP`ï¼š

``` Python
from typing import Any

# ...

class Interpreter:
    def __init__(self, bytecode: list[Bytecode]) -> None:
        # ...
        self.last_value_popped: Any = None

    # ...

    def interpret_pop(self, bc: Bytecode) -> None:
        self.last_value_popped = self.stack.pop()
```

æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œåœ¨è§£é‡Šå¼¹å‡ºæ—¶ï¼Œæˆ‘å°†å¼¹å‡ºå€¼èµ‹å€¼ç»™å±æ€§ `last_value_popped`ã€‚

ç”±äºæˆ‘ä»¬è¿˜ä¸æ”¯æŒå˜é‡æˆ–æ‰“å°ï¼Œè¯¥å±æ€§ç”¨äºè°ƒè¯•ï¼Œè¿™æ ·æˆ‘ä»¬å°±èƒ½çŸ¥é“æœ€åä»å †æ ˆä¸­å¼¹å‡ºçš„å€¼æ˜¯ä»€ä¹ˆã€‚è¿™ä¹Ÿå°†ç¡®ä¿æˆ‘ä»¬èƒ½å¤Ÿä¿®å¤æ‰€æœ‰è§£é‡Šå™¨é”™è¯¯ã€‚

äº‹å®ä¸Šï¼Œå¦‚æœå°†æ–‡ä»¶ `tests/test_interpreter.py` ä¸­è¾…åŠ©å‡½æ•° `run_computation` ä¸­çš„ `interpreter.stack.pop()` è¿”å›å€¼æ›¿æ¢ä¸º `interpreter.last_value_popped` è¿”å›å€¼ï¼Œè§£é‡Šå™¨æµ‹è¯•å°±ä¼šå…¨éƒ¨é€šè¿‡ï¼š

``` Python
def run_computation(code: str) -> int:
    tokens = list(Tokenizer(code))
    tree = Parser(tokens).parse()
    bytecode = list(Compiler(tree).compile())
    interpreter = Interpreter(bytecode)
    interpreter.interpret()
    return interpreter.last_value_popped  # <-- Changed!
```

ç°åœ¨æˆ‘ä»¬è¿è¡Œæµ‹è¯•ï¼š

``` Python
â¯ pytest .
========================== test session starts ==========================
platform darwin -- Python 3.12.0, pytest-7.4.2, pluggy-1.3.0
rootdir: /Users/rodrigogs/Documents/python
plugins: anyio-3.7.1
collected 103 items

tests/test_compiler.py ...........                                [ 10%]
tests/test_interpreter.py ....................................    [ 45%]
tests/test_parser.py ......................                       [ 66%]
tests/test_tokenizer.py ..................................        [100%]

========================== 103 passed in 0.05s ==========================
```

æˆ‘ä»¬è¿˜å¯ä»¥æ›´æ”¹æ–¹æ³• `interpret` çš„ç»“å°¾ï¼Œæ‰“å°æœ€åå¼¹å‡ºçš„å€¼è€Œä¸æ˜¯æ ˆï¼š

``` Python
class Interpreter:
    # ...

    def interpret(self) -> None:
        # ...

        print("Done!")
        print(self.last_value_popped)
```

ç°åœ¨ï¼Œæˆ‘ä»¬ä¸ä¼šåœ¨ä»£ç ä¸­æœ‰å¤šä¸ªè¯­å¥çš„åœ°æ–¹æ·»åŠ æµ‹è¯•ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰æœ‰æ•ˆçš„æ–¹æ³•æ¥ç¡®ä¿ä¸­é—´è¯­å¥äº§ç”Ÿæ­£ç¡®çš„ç»“æœï¼ˆå°½ç®¡å®ƒä»¬å¾ˆå¯èƒ½æ˜¯æ­£ç¡®çš„ï¼‰ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†ç­‰åˆ°å˜é‡èµ‹å€¼ï¼ˆä¸‹ä¸€æ­¥å°±ä¼šæœ‰ï¼ï¼‰æ—¶å†è¿›è¡Œæ£€æŸ¥ã€‚

## å›é¡¾

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡å†™äº†ç¨‹åºï¼Œä»¥ä¾¿èƒ½å¤Ÿå¤„ç†å¤šè¯­å¥ã€‚è¿™éœ€è¦ï¼š

- ä¸ºæ¢è¡Œç¬¦æ·»åŠ æ–°çš„æ ‡è®°ç±»å‹ï¼›
- ä¿®æ”¹åˆ†è¯å™¨ï¼Œä½¿å…¶å¿½ç•¥è¿ç»­çš„ç©ºè¡Œï¼›
- ä¿®æ”¹åˆ†è¯å™¨ï¼Œå¼ºåˆ¶æ‰€æœ‰ç¨‹åºä»¥æ¢è¡Œç¬¦ç»“æŸï¼›
- é‡å†™è¯­è¨€è¯­æ³•ï¼Œå…è®¸ç¨‹åºç”±å¤šä¸ªè¯­å¥ç»„æˆï¼›
- å¼•å…¥æ–°çš„æ ‘èŠ‚ç‚¹æ¥è¡¨ç¤ºç¨‹åºã€è¯­å¥å’Œä»…ç”±è¡¨è¾¾å¼ç»„æˆçš„è¯­å¥ï¼›
- ç¼–è¯‘æ–°çš„èŠ‚ç‚¹ç±»å‹ï¼›
- åˆ›å»ºä¸€ä¸ªæ–°çš„å­—èŠ‚ç è¿ç®—ç¬¦ï¼›ä»¥åŠ
- æ›´æ”¹è§£é‡Šå™¨ï¼Œä»¥å¤„ç†æ–°çš„å­—èŠ‚ç æ“ä½œç¬¦ã€‚

è¿™ç¯‡æ–‡ç« æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­ï¼Œè¯´æ˜äº†çœ‹ä¼¼ç®€å•çš„äº‹æƒ…å¦‚ä½•å¯¹è®¡åˆ’äº§ç”Ÿå·¨å¤§çš„å½±å“ã€‚

æ‚¨å¯ä»¥åœ¨æ­¤ GitHub ä»£ç åº“çš„ [v0.5.0 æ ‡ç­¾](https://github.com/mathspp/building-a-python-compiler-and-interpreter/tree/v0.5.0)ä¸­è·å–æœ¬æ–‡çš„ä»£ç ã€‚

> è¯‘è€…æ³¨ï¼šæˆ‘çš„ä»£ç åœ¨[è¿™é‡Œ](https://github.com/imkasen/bpci/tree/v0.5.0)ã€‚

## ç»ƒä¹ 

- æ›´æ”¹åˆ†è¯å™¨ï¼Œå¼€å§‹å°†å­—ç¬¦åºåˆ—è¯†åˆ«ä¸ºå˜é‡åã€‚
- ä½ èƒ½åˆ›å»ºä¸€ç»„å› ä¸ºæ˜¯å…³é”®å­—è€Œæ— æ•ˆçš„å˜é‡åå—ï¼Ÿ
- æ›´æ”¹è¯­æ³•ï¼Œä½¿ç¨‹åºç”±è®¡ç®—å’Œå˜é‡èµ‹å€¼ç»„æˆï¼Œå¹¶ç›¸åº”æ›´æ–°è§£æå™¨ã€‚
- æ›´æ”¹è¯­æ³•ï¼Œä½¿ `number` å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ•°å­—æˆ–å˜é‡å¼•ç”¨ï¼Œå¹¶ç›¸åº”åœ°æ›´æ–°è§£æå™¨ã€‚
